# sim/sim_runner.py
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
"""
SafeTalk-MPC - simulation runner

åŠŸèƒ½ï¼š
- è¯»å– DSL(JSON) -> è°ƒç”¨ build_ocp æ„å»º NLP
- è‡ªåŠ¨æ ¹æ® nlp['x'] çš„çœŸå®é•¿åº¦æ„é€ åˆå€¼
- æ±‚è§£å¹¶ç»˜å›¾/åŠ¨ç”»ï¼Œä¿å­˜æŒ‡æ ‡
- æ”¯æŒä¸¤ç§è¡¥ä¸æ–¹å¼ï¼šæœ¬åœ° JSON / LLM ç¼–è¯‘å™¨
- åŒ…æ–¹å¼ï¼ˆpython -m sem2mpc.sim.sim_runnerï¼‰ä¸è„šæœ¬æ–¹å¼ï¼ˆcd sem2mpc; python -m sim.sim_runnerï¼‰å‡å¯è¿è¡Œ
"""

import os
import sys
import json
import time
import csv
import argparse
import platform
import inspect
import numpy as np
import casadi as ca

# âœ… æ— ç•Œé¢ç¯å¢ƒä¹Ÿèƒ½å‡ºå›¾
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# --- ç»Ÿä¸€å¯¼å…¥ shimï¼šåŒ…æ–¹å¼ä¼˜å…ˆï¼Œè„šæœ¬æ–¹å¼å›é€€ ---
try:
    # åŒ…æ–¹å¼
    from sem2mpc.compiler.build_ocp import build_ocp
    from sem2mpc.sim.plot_animation import plot_trajectory_animation
    from sem2mpc.semantics.semantic_compiler import compile_from_text as _compile_from_text
except Exception:
    # è„šæœ¬æ–¹å¼
    from compiler.build_ocp import build_ocp
    from sim.plot_animation import plot_trajectory_animation
    from semantics.semantic_compiler import compile_from_text as _compile_from_text

# ç»‘å®šåå­—ï¼Œé¿å… NameError
compile_from_text = _compile_from_text

# --- Provider shim ---
_mk_ollama = None
_mk_openai = None
_mk_dashscope = None

# Ollama
try:
    from sem2mpc.semantics.providers.ollama_provider import make_ollama_provider as _mk_ollama
except Exception:
    try:
        from semantics.providers.ollama_provider import make_ollama_provider as _mk_ollama
    except Exception:
        _mk_ollama = None

# OpenAI
try:
    from sem2mpc.semantics.providers.openai_provider import make_openai_provider as _mk_openai
except Exception:
    try:
        from semantics.providers.openai_provider import make_openai_provider as _mk_openai
    except Exception:
        _mk_openai = None

# DashScope
try:
    from sem2mpc.semantics.providers.dashscope_provider import make_dashscope_provider as _mk_dashscope
except Exception:
    try:
        from semantics.providers.dashscope_provider import make_dashscope_provider as _mk_dashscope
    except Exception:
        _mk_dashscope = None



# -------------------------
# å·¥å…·å‡½æ•°
# -------------------------
def _load_json(path: str):
    with open(path, "r", encoding="utf-8-sig") as f:
        return json.load(f)

def _save_json(obj, path: str):
    d = os.path.dirname(path)
    if d and not os.path.isdir(d):
        os.makedirs(d, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def _ensure_dir(p: str):
    d = os.path.dirname(p)
    if d and not os.path.isdir(d):
        os.makedirs(d, exist_ok=True)

def _ensure_meta(nlp, meta):
    if isinstance(meta, dict) and 'N' in meta:
        if 'bounds' not in meta or 'lbg' not in meta['bounds'] or 'ubg' not in meta['bounds']:
            ng = int(nlp['g'].size1())
            meta.setdefault('bounds', {})
            meta['bounds']['lbg'] = [0.0] * ng
            meta['bounds']['ubg'] = [1e9] * ng
        return meta
    try:
        N, nx, nu = meta
    except Exception:
        raise RuntimeError("build_ocp å¿…é¡»è¿”å› (nlp, meta)ï¼Œå…¶ä¸­ meta è‡³å°‘åŒ…å« {N, nx, nu} æˆ–ç­‰ä»·å…ƒç»„ã€‚")
    ng = int(nlp['g'].size1())
    return {'N': int(N), 'nx': int(nx), 'nu': int(nu),
            'bounds': {'lbg': [0.0]*ng, 'ubg': [1e9]*ng}, 'obstacle': None}

def _jsonable_patch(patch: dict) -> dict:
    out = {}
    for k, v in (patch or {}).items():
        out[k] = list(v) if isinstance(v, tuple) else v
    return out

def _append_csv_log(csv_path: str, row: dict):
    header = list(row.keys())
    exists = os.path.isfile(csv_path)
    _ensure_dir(csv_path)
    with open(csv_path, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=header)
        if not exists:
            w.writeheader()
        w.writerow(row)

def _looks_like_json_text(s: str) -> bool:
    if not isinstance(s, str):
        return False
    t = s.lstrip()
    return t.startswith("{") or t.startswith("[")

def _is_json_path(s: str) -> bool:
    if not isinstance(s, str):
        return False
    t = s.strip().strip('"').strip("'")
    return t.lower().endswith(".json") or ("/" in t) or ("\\" in t)

def _load_patch_from_arg(arg: str):
    if _looks_like_json_text(arg):
        try:
            return json.loads(arg)
        except Exception as e:
            raise ValueError(f"Inline JSON patch is invalid: {e}")
    if _is_json_path(arg):
        p = arg.strip().strip('"').strip("'")
        if os.path.isfile(p):
            return _load_json(p)
        abs_p = os.path.abspath(p)
        if os.path.isfile(abs_p):
            return _load_json(abs_p)
        raise FileNotFoundError(f"Patch file not found: {arg} (abs: {abs_p})")
    raise ValueError("When --llm none, the second argument must be a JSON file path or an inline JSON object.")

def _deep_merge(dst: dict, src: dict) -> dict:
    for k, v in (src or {}).items():
        if isinstance(v, dict) and isinstance(dst.get(k), dict):
            _deep_merge(dst[k], v)
        else:
            dst[k] = v
    return dst


# -------------------------
# ğŸ” å·®å¼‚æŠ¥å‘Šï¼ˆæ›´ç¨³ï¼‰ï¼šç›´æ¥æ¯”è¾ƒ base vs patched
# -------------------------
_NUM_KEYS_HINT = {"constraints", "speed_cap", "weights", "obstacle", "u_rate_weight"}

def _dict_diff(a, b, prefix=""):
    diffs = []
    a = a if isinstance(a, dict) else {}
    b = b if isinstance(b, dict) else {}
    keys = set(a.keys()) | set(b.keys())
    for k in sorted(keys):
        p = f"{prefix}.{k}" if prefix else k
        av, bv = a.get(k, None), b.get(k, None)
        if isinstance(av, dict) or isinstance(bv, dict):
            diffs += _dict_diff(av if isinstance(av, dict) else {}, bv if isinstance(bv, dict) else {}, p)
        else:
            if av != bv:
                diffs.append((p, av, bv))
    return diffs

def _print_diff_explanation(base_task: dict, patched_task: dict):
    diffs = _dict_diff(base_task, patched_task)
    if not diffs:
        print("â„¹ï¸ æœ¬æ¬¡æœªæ£€æµ‹åˆ° DSL å‚æ•°å˜åŒ–ï¼ˆå¯èƒ½ LLM/å›é€€æœªç”Ÿæˆè¡¥ä¸ï¼‰ã€‚")
        return
    print("ğŸ” æœ¬æ¬¡è¯­ä¹‰æŒ‡ä»¤å¯¼è‡´çš„ DSL å‚æ•°æ”¹åŠ¨ï¼š")
    for p, old, newv in diffs:
        # åªæ‰“å°å’Œ MPC ç›¸å…³çš„å¸¸è§é”®ï¼ˆå¯æŒ‰éœ€æ”¾å®½ï¼‰
        if p.split(".")[0] in _NUM_KEYS_HINT:
            try:
                old_s = json.dumps(old, ensure_ascii=False)
                new_s = json.dumps(newv, ensure_ascii=False)
            except Exception:
                old_s, new_s = str(old), str(newv)
            print(f" - {p}: {old_s} â†’ {new_s}")


# -------------------------
# æ±‚è§£ + ä½œå›¾
# -------------------------
def solve_and_plot(task_json_path, out_prefix='mpc'):
    print('ğŸ› ï¸ Building MPC problem from DSL...')
    build_ret = build_ocp(task_json_path)
    if isinstance(build_ret, (list, tuple)) and len(build_ret) == 2:
        nlp, meta = build_ret
    else:
        raise RuntimeError("build_ocp å¿…é¡»è¿”å› (nlp, meta)")

    meta = _ensure_meta(nlp, meta)
    N, nx, nu = meta['N'], meta['nx'], meta['nu']
    lbg, ubg = meta['bounds']['lbg'], meta['bounds']['ubg']

    solver = ca.nlpsol('solver', 'ipopt', nlp, {
        'ipopt.print_level': 0, 'print_time': 0,
        'ipopt.max_iter': 400, 'ipopt.tol': 1e-6
    })

    n_dec = int(nlp['x'].size1())
    base_len = nx * (N + 1) + nu * N
    extra = n_dec - base_len
    if extra < 0:
        raise RuntimeError(f"Internal error: decision size smaller than X/U block. n_dec={n_dec}, base_len={base_len}")

    x_init = ca.DM.zeros((nx, N + 1))
    u_init = ca.DM.zeros((nu, N))
    init_guess = ca.vertcat(ca.reshape(x_init, -1, 1), ca.reshape(u_init, -1, 1))
    if extra > 0:
        init_guess = ca.vertcat(init_guess, ca.DM.zeros(extra, 1))

    print('ğŸš€ Solving MPC...')
    t0 = time.time()
    sol = solver(x0=init_guess, lbg=lbg, ubg=ubg)
    t1 = time.time()

    if 'x' not in sol:
        raise RuntimeError("âŒ IPOPT æœªè¿”å›è§£å‘é‡ x")

    x_opt = ca.reshape(sol['x'][:nx * (N + 1)], nx, N + 1)
    xs = x_opt.T.full()
    xs_xy = xs[:, :2]

    task_cfg = _load_json(task_json_path)
    goal = np.array(task_cfg.get('goal', [2, 1, 0, 0, 0]))[:2]
    end_err = float(np.linalg.norm(xs_xy[-1] - goal))
    tot_time = t1 - t0

    obstacle = None
    min_dist = None
    if meta.get('obstacle'):
        cx = float(meta['obstacle']['center'][0])
        cy = float(meta['obstacle']['center'][1])
        r = float(meta['obstacle']['radius'])
        d = np.sqrt((xs_xy[:, 0] - cx) ** 2 + (xs_xy[:, 1] - cy) ** 2)
        min_dist = float(np.min(d))
        obstacle = (cx, cy, r)

    plt.figure(figsize=(6, 6))
    plt.plot(xs_xy[:, 0], xs_xy[:, 1], 'b-o', ms=3, label='trajectory')
    plt.scatter([xs_xy[0, 0]], [xs_xy[0, 1]], c='g', s=60, label='start')
    plt.scatter([goal[0]], [goal[1]], c='r', s=60, label='goal')
    if obstacle:
        circ = plt.Circle((obstacle[0], obstacle[1]), obstacle[2], color='gray', alpha=0.35, label='obstacle')
        plt.gca().add_patch(circ)
    plt.axis('equal'); plt.grid(True); plt.legend(); plt.title('SafeTalk-MPC Trajectory')
    fig_path = f"{out_prefix}_result.png"
    _ensure_dir(fig_path)
    plt.savefig(fig_path, dpi=150); plt.close()
    print(f"ğŸ“· saved {fig_path}")

    if xs.shape[0] >= 3:
        try:
            anim_path = f"{out_prefix}_anim.mp4"
            plot_trajectory_animation(xs[:, :3], anim_path, obstacle=obstacle or (1.0, 0.5, 0.3))
            print(f"ğŸ¥ saved {anim_path}")
        except Exception as e:
            print(f"âš ï¸ åŠ¨ç”»å¯¼å‡ºå¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")

    metrics = {'N': int(N),
               'end_position_error': end_err,
               'min_obstacle_distance': min_dist,
               'solve_time_sec': tot_time}
    _save_json(metrics, f"{out_prefix}_metrics.json")
    print("ğŸ“‘ metrics:", metrics)
    return metrics


# -------------------------
# Provider æ„é€ 
# -------------------------
def _make_provider(args):
    if args.llm == 'ollama':
        if _mk_ollama is None:
            return None
        return _mk_ollama(
            model=args.model,
            base_url=args.base_url,
            temperature=args.temp,
            num_predict=256,
            seed=args.seed,
            save_dir="llm_logs" if args.save_llm else None,
            timeout=120,
            max_retries=2,
        )
    if args.llm == 'openai':
        if _mk_openai is None:
            print("âš ï¸ openai provider ä¸å¯ç”¨ï¼ˆæœªæ‰¾åˆ°æ¨¡å— semantics.providers.openai_providerï¼‰")
            return None
        # API Key ä»ç¯å¢ƒå˜é‡è¯»å–
        return _mk_openai(
            model=args.model,
            api_base=args.base_url,
            api_key=os.getenv("OPENAI_API_KEY", ""),
            temperature=args.temp,
            save_dir="llm_logs" if args.save_llm else None,
            timeout=120,
            max_retries=2,
        )
    if args.llm == 'dashscope':
        if _mk_dashscope is None:
            print("âš ï¸ dashscope provider ä¸å¯ç”¨ï¼ˆæœªæ‰¾åˆ°æ¨¡å— semantics.providers.dashscope_providerï¼‰")
            return None
        return _mk_dashscope(
            model=args.model,
            api_key=os.getenv("DASHSCOPE_API_KEY", ""),
            temperature=args.temp,
            save_dir="llm_logs" if args.save_llm else None,
            timeout=120,
            max_retries=2,
        )
    return None


# -------------------------
# CLI
# -------------------------
def build_arg_parser():
    p = argparse.ArgumentParser(description="SafeTalk-MPC simulation runner")
    p.add_argument('task', nargs='?', default='dsl/example_task_curve_01.json',
                   help='DSL JSON path (default: dsl/example_task_curve_01.json)')
    p.add_argument('instruction', nargs='?', default=None,
                   help='Natural language instruction / JSON patch / patch file path')
    p.add_argument('--out', default='mpc', help='output file prefix (default: mpc)')

    # LLM ç›¸å…³
    p.add_argument('--llm', default='ollama', choices=['none', 'ollama', 'openai', 'dashscope'],
                   help='LLM backend (default: ollama)')
    p.add_argument('--model', default='qwen2.5:7b-instruct', help='model name (ollama: qwen/llama; openai: gpt-4o-mini ç­‰)')
    p.add_argument('--k', type=int, default=1, help='(reserved) samples per model (default: 1)')
    p.add_argument('--temp', type=float, default=0.0, help='LLM temperature (default: 0.0)')
    p.add_argument('--seed', type=int, default=42, help='sampling seed (default: 42)')

    # URLï¼šå¯¹ ollama æ˜¯ http://127.0.0.1:11434ï¼›å¯¹ openai å¯å¡«è‡ªå®šä¹‰åä»£ï¼›å¯¹ dashscope å¿½ç•¥
    p.add_argument('--base-url', default='http://127.0.0.1:11434', help='Ollama/OpenAI base URL')
    p.add_argument('--save-llm', action='store_true', help='save raw LLM logs to llm_logs/')
    p.add_argument('--risk', default='high', choices=['low', 'med', 'high'],
                   help='risk hint for semantics (default: high)')
    return p


def main():
    args = build_arg_parser().parse_args()
    task_path = args.task
    out_prefix = args.out
    instruction = args.instruction

    # ===== åˆ†æ”¯ 1ï¼š--llm noneï¼Œæœ¬åœ°è¡¥ä¸ =====
    if instruction is not None and args.llm == 'none':
        print(f"ğŸ—‚ï¸ Local patch mode (--llm none). Patch arg: {instruction}")
        patch_obj = _load_patch_from_arg(instruction)
        base_task = _load_json(task_path) if os.path.isfile(task_path) else json.loads(task_path)
        patched_task = _deep_merge(json.loads(json.dumps(base_task)), patch_obj)
        _save_json(_jsonable_patch(patch_obj), "last_patch.json")
        _save_json(patched_task, "_tmp_task.json")
        print("ğŸ§© Local patch å·²ä¿å­˜ï¼šlast_patch.json")
        print("ğŸ§¾ Patched DSL å·²ä¿å­˜ï¼š_tmp_task.json")

        # âœ… å·®å¼‚æŠ¥å‘Šï¼ˆä¸ä¾èµ– patch_objï¼‰
        _print_diff_explanation(base_task, patched_task)

        metrics = solve_and_plot("_tmp_task.json", out_prefix=out_prefix)

    # ===== åˆ†æ”¯ 2ï¼šLLM è¯­ä¹‰ç¼–è¯‘ï¼ˆollama/openai/dashscopeï¼‰ =====
    elif instruction is not None and args.llm != 'none':
        print(f"ğŸ—£ï¸ Instruction: {instruction}")

        provider = _make_provider(args)
        original_task = _load_json(task_path) if os.path.isfile(task_path) else task_path

        try:
            patched_task, patch = compile_from_text(
                original_task, instruction,
                context={'risk_hint': args.risk},
                provider=provider
            )
        except Exception as e:
            print(f"âš ï¸ LLM ç¼–è¯‘å¤±è´¥ï¼Œæ”¹ç”¨æœ¬åœ°è§„åˆ™å›é€€ï¼š{e}")
            patched_task, patch = compile_from_text(
                original_task, instruction,
                context={'risk_hint': args.risk},
                provider=None
            )

        _save_json(_jsonable_patch(patch), "last_patch.json")
        _save_json(patched_task, "_tmp_task.json")
        print("ğŸ§© LLM patch å·²ä¿å­˜ï¼šlast_patch.json")
        print("ğŸ§¾ Patched DSL å·²ä¿å­˜ï¼š_tmp_task.json")
                # ğŸ”– æ‰“å°è¡¥ä¸æ¥æº/è§„åˆ™/å¼ºåº¦
        origin = patch.get("_origin", "unknown")
        rules  = patch.get("_rules", [])
        inten  = patch.get("_intensity", "")
        print(f"ğŸ“Œ è¡¥ä¸æ¥æº: {origin}" + (f"  (è§„åˆ™: {', '.join(rules)}; å¼ºåº¦: {inten})" if rules or inten else ""))


        # âœ… å·®å¼‚æŠ¥å‘Šï¼ˆæœ€ç¨³ï¼‰ï¼šç›´æ¥å¯¹æ¯” base vs patched
        base_task_dict = original_task if isinstance(original_task, dict) else _load_json(original_task)
        _print_diff_explanation(base_task_dict, patched_task)

        metrics = solve_and_plot("_tmp_task.json", out_prefix=out_prefix)

    # ===== åˆ†æ”¯ 3ï¼šæ— è¡¥ä¸ =====
    else:
        print("ğŸ—£ï¸ No instruction. Run base task.")
        metrics = solve_and_plot(task_path, out_prefix=out_prefix)
    
    # ï¼ˆå¯é€‰ï¼‰æŠŠæ¥æºå†™è¿› CSV
    try:
        origin = patch.get("_origin", "")
        rules = ",".join(patch.get("_rules", []))
        inten = patch.get("_intensity", "")
    except NameError:
        origin = rules = inten = ""
    row = {
        "time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "llm": args.llm,
        "model": args.model,
        "temp": args.temp,
        "seed": args.seed,
        "instruction": instruction or "",
        "task": task_path,
        "end_err": metrics.get("end_position_error"),
        "min_dist": metrics.get("min_obstacle_distance"),
        "solve_time": metrics.get("solve_time_sec"),
        "N": metrics.get("N"),
        "machine": platform.platform(),
        "origin": origin,
        "rules": rules,
        "intensity": inten,
    }
    try:
        _append_csv_log("llm_runs.csv", row)
        print("ğŸ§¾ appended log to llm_runs.csv")
    except Exception as e:
        print(f"âš ï¸ CSV è®°å½•å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")

    print('âœ… Done.')


if __name__ == '__main__':
    main()
